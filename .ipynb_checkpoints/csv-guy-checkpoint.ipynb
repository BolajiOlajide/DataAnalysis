{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlanta_records = pd.read_csv('atlanta.csv', header=None)\n",
    "chicago_records = pd.read_csv('chicago.csv', header=None)\n",
    "dallas_records = pd.read_csv('dallas.csv', header=None)\n",
    "oakland_records = pd.read_csv('oakland.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "filenames = glob.glob(current_dir + \"/*.csv\")\n",
    "# print(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source_column(frame, col_name, file_path):\n",
    "    # if file_path is a filepath for example /Users/test/Dev/csv_panda/dallas.csv\n",
    "    # the command file_path.split('/') is used to split the pathname with the / as delimiter \n",
    "    # into an array of strings, the result should look like this \n",
    "    # ['Users', 'test','Dev', 'csv_panda','dallas.csv'], the [-1] is used to get the last element in the array\n",
    "    # which happens to be name of the csv itself, which usually is the name of the city and the file format.\n",
    "    # Next we call the `split` method on the this and with the '.' as delimiter. This should give us something\n",
    "    # like ['dallas', 'csv']. Then we access the first element in the array which is the city itself and the result\n",
    "    # should be 'dallas'\n",
    "    frame[col_name] = file_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_quarter(quarter):\n",
    "    no_of_years = int(int(quarter)/4)\n",
    "    year = 1970 + no_of_years\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_year_column(row):\n",
    "    return get_year_from_quarter(row[2])\n",
    "\n",
    "def append_year(frame, col):    \n",
    "    quarters = frame[col]\n",
    "    column_name = col + \"_year\"\n",
    "    frame[column_name] = frame.apply(add_year_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_year2_column(row):\n",
    "    return get_year_from_quarter(row[3])\n",
    "\n",
    "def append_year2(frame, col):    \n",
    "    quarters = frame[col]\n",
    "    column_name = col + \"_year\"\n",
    "    frame[column_name] = frame.apply(add_year2_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Complete the function below to read multiple files into a single pandas\n",
    "#    data frame.  This function takes three arguments:\n",
    "#    - a string 'dir_path'\n",
    "#    - an array of strings that will be used as column names\n",
    "#    - a string name of a new column\n",
    "#    Your function should return a single DataFrame with the column names\n",
    "#    as specified in the column_names argument.  The resulting frame should\n",
    "#    be indexed with unique integers, starting at 0.  For now, you can ignore\n",
    "#    the third argument.\n",
    "#    A sample data row is:\n",
    "#    0     2550     3300       38   54\n",
    "def read_all_files(dir_path, column_names, source_column=''):\n",
    "    data_files = glob.glob(dir_path + \"/*.csv\")\n",
    "    frames = []\n",
    "    for f in data_files:\n",
    "        #FILL THIS IN\n",
    "        #CREATE A NEW DATAFRAME CALLED new_frame FROM FILE f and columns\n",
    "        new_frame = pd.DataFrame(data = pd.read_csv(f, header=None))\n",
    "        new_frame.columns = column_names\n",
    "        add_source_column(new_frame, 'city', f)\n",
    "        append_year(new_frame, 'purchase_date')\n",
    "        append_year2(new_frame, 'sales_date')\n",
    "        frames.append(new_frame)\n",
    "    return pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = read_all_files(current_dir, ['purchase_price', 'sales_price', 'purchase_date', 'sales_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_sales(frame, period):\n",
    "    result = frame.query('sales_date=={0}'.format(period))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit(row):\n",
    "    return row[1] - row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_on_fast_sales(frame,period):\n",
    "    sales = fast_sales(frame, period)\n",
    "    sales[\"profit\"] = frame.apply(calculate_profit, axis=1)\n",
    "    return sales[\"profit\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1164.3993260320135"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_on_fast_sales(frame,54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_by_column(frame, col_name):\n",
    "    return frame.groupby('city').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "atlanta     8459\n",
       "chicago    15530\n",
       "dallas      6669\n",
       "oakland     8066\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_by_column(frame, 'city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
